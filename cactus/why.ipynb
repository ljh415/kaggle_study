{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.layers import Conv2D, Input, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from glob import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.zip',\n",
       " 'aerial-cactus-identification.zip',\n",
       " 'train.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'why.ipynb',\n",
       " 'test',\n",
       " 'train',\n",
       " 'sample_submission.csv',\n",
       " 'test.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs = glob('train/*')\n",
    "len(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs = glob('test/*')\n",
    "len(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터확인\n",
    "This dataset contains a large number of 32 x 32 thumbnail images containing aerial photos of a columnar cactus (Neobuxbaumia tetetzo). Kaggle has resized the images from the original dataset to make them uniform in size. The file name of an image corresponds to its ```id```.  \n",
    "  \n",
    "You must create a classifier capable of predicting whether an images contains a cactus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = tf.io.read_file(train_imgs[0])\n",
    "img = tf.image.decode_image(img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train/a8da764c87b9c67630b4a24a42eeb2f4.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/4d502fd57fe2fe31318f8246a343a57f.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000940378805c44108d287872b2f04ce.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0017242f54ececa4512b4d7937d1e21e.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ee6d8564003107853118ab87df407.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002e175c3c1e060769475f52182583d0.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0036e44a7e8f7218e9bc7bf8137e4943.jpg</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  000940378805c44108d287872b2f04ce.jpg         0.5\n",
       "1  0017242f54ececa4512b4d7937d1e21e.jpg         0.5\n",
       "2  001ee6d8564003107853118ab87df407.jpg         0.5\n",
       "3  002e175c3c1e060769475f52182583d0.jpg         0.5\n",
       "4  0036e44a7e8f7218e9bc7bf8137e4943.jpg         0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 크기는 32x32, 3채널..? 일 것이다.  채널수가 다르다면 이후에 에러가 발생할 수 있음.\n",
    "- train에 대한 label은 train.csv에 존재\n",
    "- ```id```를 사용해서 submission파일 생성, ```id```는 이미지의 파일명과 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼.. 사진에 대한 어... 정보는 train에 있는 사진을 읽어서 numpy로 전달하고..  \n",
    "어.... label은 csv에 id로 접근해서...데이터셋을... 만드나?  \n",
    "1. 먼저 csv에서 파일명과 label을 가져와서 input_paths리스트를 새롭게 생성한다.\n",
    "    - fname(train_img_id)의 경우 앞에 train dataset의 경로를 명시해주도록 os.path.join을 활용\n",
    "    - train, valid 나누기\n",
    "2. tf.data.Dataset을 사용하면 간단하게 리스트로 전달해주고 dataset을 만들 수 있다.\n",
    "    - Dataset을 생성하고 값을 확인하려면 다음과 같이 입력\n",
    "        ```python\n",
    "        n = next(iter(dataset))\n",
    "        ```\n",
    "3. 추가로 경로로 만든 dataset을 map함수를 사용해서 경로 => 이미지로 읽어주는 함수를 적용\n",
    "    - read_file 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 17500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_id = train_csv['id']\n",
    "train_img_label = train_csv['has_cactus']\n",
    "len(train_img_id), len(train_img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15512d830e341f5a6bfddf45229fb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_paths = []\n",
    "for fname, label in tqdm(zip(train_img_id, train_img_label)):\n",
    "    input_paths.append((os.path.join('train', fname), label))\n",
    "    \n",
    "len(input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train/0004be2cfeaba1c0361d39e2b000257b.jpg', 1),\n",
       " ('train/000c8a36845c0208e833c79c1bffedd1.jpg', 1),\n",
       " ('train/000d1e9a533f62e55c289303b072733d.jpg', 1),\n",
       " ('train/0011485b40695e9138e92d0b3fb55128.jpg', 1),\n",
       " ('train/0014d7a11e90b62848904c1418fc8cf2.jpg', 1),\n",
       " ('train/0017c3c18ddd57a2ea6f9848c79d83d2.jpg', 1),\n",
       " ('train/002134abf28af54575c18741b89dd2a4.jpg', 0),\n",
       " ('train/0024320f43bdd490562246435af4f90b.jpg', 0),\n",
       " ('train/002930423b9840e67e5a54afd4768a1e.jpg', 1),\n",
       " ('train/00351838ebf6dff6e53056e00a1e307c.jpg', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_paths[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data.Dataset 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.array(input_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'train/0004be2cfeaba1c0361d39e2b000257b.jpg', shape=(), dtype=string) \n",
      " tf.Tensor(b'1', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "n = next(iter(dataset))\n",
    "print(n[0], '\\n', n[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAei0lEQVR4nO2de2zd5Znnv4/vdzu2E9ux49zIlUBC6uU6JZlpd2ARaumsqECaDn+gYaQpu1tp9g/UlbatdqTtTKetoBohhRZNZqdpS6cgUAftDtDdLS0USCi5QCBXJ3HsxLnZPr7fnv3Dh50A7/e1E9vHmb7fjxTFfr9+z3n9nvP4d877Pc/zmLtDCPG7T95CL0AIkRsU7EIkgoJdiERQsAuRCAp2IRJBwS5EIhTMZrKZ3Q3gcQD5AL7v7t+M/Xx5eZnXLKq+4vvJzwsvc3Jyks4ZGxuj2sQEn2cRJzIvPz+8jsjtFRREtjhyXx4R88yoZnlX/veb31p8HcPDw1QrLS0JjucZX9/g4CDViooKqZZPHhcAKCosCo7HnjsxJibGqRZzsSMPGYyIMVs8jzzOFy5dQmZgIHiDVx3sZpYP4G8B/FsAHQDeMrMX3P09NqdmUTW+/B8fDmqxza+uqA2O9/fzJ8e5s+eo1nOpn2p5k/xRqaqsCa+jd4DOWbx4MdUmxmJPHP5AFxXyJ3dpaSnVGLEn4vgk/6P5wQcHqXbDpo3B8dj63tnzNtVaWlqoVlvFLyBLly4Njo8M8T9Usb3v6b1ItYmJCarF/ugzLXbBKi8vD47/t+89TufM5mX8zQCOuPsxdx8F8GMAn5/F7Qkh5pHZBHszgFOXfd+RHRNCXIPMJthDL/4+8frHzB4xs91mtntggL/sFkLML7MJ9g4Ayy77vgVA58d/yN13uHubu7eVl5fN4u6EELNhNsH+FoA1ZrbSzIoAPADghblZlhBirrnq03h3HzezRwH8L0xZb0+7+7uxOZOTk9ReWbNmDZ83Fj4u3rPnt3ROcxM/PnDnx88lBfzVR2dHV3C8ribsFgBAcXEx1TLDI1RraGig2oXz3VRjJ7hDQ0N0Tl0dXz8m+cn0hg0bqMZ+7/Pnz1/V7V133XVUy1zqoVpvb29wvK8nPA4AdXV1VIu5CYsWLaLa8ePHqdbY2BgcZ2sHgP7+sKMUc7Vm5bO7+4sAXpzNbQghcoM+QSdEIijYhUgEBbsQiaBgFyIRFOxCJMKsTuOvlJKSEqy9LmyxxTLHppy9T3LXXXfRGfve2Ue1mLXSefIM1QoLw5lXhw4donPWr19Ptf5MhmqZDLddOjo6qLZu3brg+MQ4T6o4ceIEv70NayPrOEm1EZIRNzTE7UaL2HzHjh2jWnlxOMMOALq7wzZlfS1/DsSy+VpbW6l28SJPksnP41l7mb5wIlVlZSWd097eHhwfH+fJOLqyC5EICnYhEkHBLkQiKNiFSAQFuxCJkNPT+P5MP1599dWgFkv8uHQpfDK96fob6RxWAw2IJyy0NPHyR0WF4dssLebJMxWl4fJBAFBM6qMBccegr6+PaqOjo2HBudtRXMxPii/2XKLa+vX8pL60JLxXLIEDAGySnyQPDPDSXzUV/NR67drwGsdGyD4BqKqqotquXbuotm3bNqrV19dTLUNcmdjpPit3VljIQ1pXdiESQcEuRCIo2IVIBAW7EImgYBciERTsQiRCTq23mppqfO5znwtqFRUVdN7SxnA9uYEBXletuIjXCmtpWU61fJJ0A/CEhfFI547CAl6DLpb4EesuUld/5TXvYvs7Ps5tKNaaCABGRvj+T5L1x36v8YgdNjLCE2jyIvvIrL7BwYgFGPmdV61adcX3BQCnuz5RePn/w+raFRfz53A9sd4KCriNqiu7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEmFW1puZtQPIAJgAMO7ubbGfHxgcxJ49e4JaTU0Nnfeb194Ijg8Pc6umrJRbTWVlPBOtribW+ic8ryhid+Tnc83HuGUUtcoiVh/LeovVVRsfH6dazF7Li1wqxsg6ohYa3w64c/HSBZ4dVkqsyJj1FstQO3XqFNWqq6upxuoXAkBZWThrMpb1xvaDtf8C5sZn/3135w28hBDXBHoZL0QizDbYHcA/m9keM3tkLhYkhJgfZvsy/g537zSzJQBeMrP33f2Xl/9A9o/AIwBQXc0riggh5pdZXdndvTP7fzeA5wDcHPiZHe7e5u5tZeW8fJMQYn656mA3s3Izq/zwawB/CODAXC1MCDG3zOZlfAOA57IZQgUAdrn7/4xNKCwoQMPiJUEtVlBw9erVwfHeXt4+aXiI23LLli2jWmkRz1IrLGQa/5vJbBUAGB+NZLZFCk7mg2dlMUtmJLIfBQX8aRDLiOvp6aFaKWnJNDg4SOdgkluAMSvywL79VGNW2aKITWbGMx83brqBavkRe+3w4cNU27JlS3B8cpIXCWUWZsyivOpgd/djADZf7XwhRG6R9SZEIijYhUgEBbsQiaBgFyIRFOxCJEJOC05OTk5imFgvRUW879n+d/YGxy/0hHvAAcClS7xHWeOxpVQ7/P4hqrHMvCVLGumcRYu4hTYxxq2mvLxIz65IdhjLehsa4FlvsSKQBQX8esCKWwKgFmssK6uijPfni2Wb7d+7j2q333471RgxuzS2/vJynk3Z2tpKtZiFeaX3lRdJRdSVXYhEULALkQgKdiESQcEuRCIo2IVIhJyexk9MTKKvJ5y8kh9JxqhbFK4JNjHBj6UX1/JTcHZiDQDr1q+l2tKmcBuqWF21vj6erFNfG27hM91txlpUnTt3LjheHqnJFztFLi3mLknsZJolccRO8M+eDa8dAMbHeVJIXR3fx4ICvn5Gd3c31WLJKTEHqLY+7E4A/DSepzsBHZ1nguOjkcdEV3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkQk6tt8L8AiwmdlPnmbCVAAATY2G7wyIJITGtqamJaufOXaDa0HA4iScvUrOsvr6WameIfQLELZ4853+jM5mw1Tc2wpNulizhtlBZGbfsLl7kjYCYfVVaWkrnxNonNTbyZKMN69ZTjdlhZWV8HbF6d2x/AeCDDz6gWqxXFvu9YwlKJSXhpCElwgghFOxCpIKCXYhEULALkQgKdiESQcEuRCJMa72Z2dMA7gXQ7e6bsmO1AH4CYAWAdgBfdHee8pNlbGwMXR1hu6mqhtsdfX19wfHJSKubWNZYx0lez6y2NpxhB/DWOrFMLrZ2AMAEt9fyjec8ne44TbXx8bDFVt/Kf69TJ05SrSCP24qZDG/ZxWyj4mJuecVsufPnuc03Oswfa3abLDsQANau5ZmP7x7k9lps/Xfe+XtU++lPfxoc39r2KTonth+MmVzZ/w7A3R8bewzAK+6+BsAr2e+FENcw0wZ7tt/6xY8Nfx7AzuzXOwHcN8frEkLMMVf7nr3B3bsAIPs//wiWEOKaYN4P6MzsETPbbWa7BwaH5vvuhBCEqw32s2bWBADZ/2kdH3ff4e5t7t5WHvk8shBifrnaYH8BwEPZrx8C8PzcLEcIMV/MxHr7EYDtAOrNrAPA1wB8E8AzZvYwgJMA7p/JneXn52MRaaF04iS3fxoaGoLjE+CZXLGModGIrZWfz62mQdK66uDB9+mcwsJCqo0P8/V3dZ2l2o2bNlONZe299trrdM7AALfQWHYVEN/j5cuXB8c7OjronCWRDMFYG6e33niTakND4beObBwAjh49SrXY78ysWQA4dIi3FVu3bl1w/EwkE7Sqqio4Hst6mzbY3f1BIn1murlCiGsHfYJOiERQsAuRCAp2IRJBwS5EIijYhUiEnBachANGEr3GIv3X+np7g+MWsxkiveO6OruoduzYMaoxC3DFirDNBABvvvkW1dau4tlV589/PB3hX2AWIAA4yaSzSW4LrVq+gmqx4otlZWVUYxlgveSxBIAbIpbis88+S7XVq1ZRraoqbPXGHufY/t52221U27dvH9XGI/tfUhbutVdVs4jOYcUtY/33dGUXIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIuTUejMzmlVWURq2HwBgeCCcodTc2kLnjEeyk27cdAPVKqr5OgpJYcmGBt477o/+6N9TLZb1NpDh9k9ry0qqjRILs7aa2zixvnL9QzwjLlZg8b333guOx7Ledu/eTTVmewJxy+vUqXBx0cZGXlyJ9YcDgDff5Bl2MSuyqKiIaqw4aiwD81OfChejfO6lf6JzdGUXIhEU7EIkgoJdiERQsAuRCAp2IRIhp6fxo6NjOH2qM6hNOj8RZifMB9/jtd8yAxmqxZI7evp4osbKleFT8OrqE3TO66//hmrLmlupVllRTbWBzDCfV1kZHC8t4rXkYklDk8YTOGKnxa2t4d/trrvuonM+eO8g1T772c9SrfDujzcs+hfYY82eU0DcZXj++eeodvz4caodOXKEaqxeX6yeXH9/f3B8ItJSTFd2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJMJM2j89DeBeAN3uvik79nUAfwrgXPbHvuruL053WxMTE+i51BfURkZ5O57u7nDfyI2bNtA5119/PdUGh/l9xZJCLD/cNmrrlq10zj133xO5LypheIhbQ5Xl4dY/ADA0FE6qyHPe8iqWwJFfxJ8iMfuK2UaxVlM33ngj1WKP5z/9/OdUY/cXa//U08cTYcZG+O+8tKWZajGMtCOLtZPKZMLW8uQkTwCbyZX97wCEjMzvuvuW7L9pA10IsbBMG+zu/ksAvNSpEOJfBbN5z/6ome0zs6fNjCdLCyGuCa422J8EsBrAFgBdAL7NftDMHjGz3Wa2e3iEf8xTCDG/XFWwu/tZd59w90kATwG4OfKzO9y9zd3bSor557OFEPPLVQW7mV1eh+kLAA7MzXKEEPPFTKy3HwHYDqDezDoAfA3AdjPbAsABtAP4s5ncWXFRMVa2hjPHnnr6KTpv27ZtwfGhQd7q5tjhdqpVVPOst1hGXFNjY3D81f/7KzonVlftzju3Uy1mAVZVhlsaAbwe3qJF/Filq/sM1RbX1lEt088zBM+dOxccj7UnYrXYAGDXj/6BarG9Yhll4+O8/l9Z5DnQGmn1dewEbykVsylZfbrycl4Psag0PIfZeMAMgt3dHwwM/2C6eUKIawt9gk6IRFCwC5EICnYhEkHBLkQiKNiFSIScFpx0d0yQtkxPfPcJOu/goQ+C4xcuhO0dACgoKqRazIbKL+JFFM90ng2Os1Y8AC9SCQDVkZZMBw/y4ovM1gKA9vb24HhppL3WUKTFU0Gk6OHwMP9EZGFheP937dpF53zjG9+g2sWLPD3j/vvvpxpr/5QXKbIZywLMDPJCpjGrjGVuAsDGjRuD4zG7jsURz5PTlV2IZFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJkFPrraCgAIsXLw5qzKoBgDVrVgfHb7ppM50zNsGzmkZGeLHBuiXh9QE8oyhm5cXsk5ISbvHccsstVLtw4QLVWJHCWAHLlpYWqp09G7YbAeDAu/u4diCc9fyX//0v6ZympnDGHgC03dJGtcGRQao1t4aLQJ48eZLOOdvNs/kaSeYjEM/aa2hooBorfhmzAJmVxyw5QFd2IZJBwS5EIijYhUgEBbsQiaBgFyIRcnoaPzY2hs7OzqBWVcVbGl3qCZ8+nzp9ms5x8FPJ6hpew+30yy9TbfPWm4LjrBUPED+NHxvja4zVwtu7dy/Vqqurg+P9GX5ife48P3Hv6emh2vbt26nG3JVYTb7Vq8OuC8CTRQDgyJEjVGPJKcXFxXROrE5erH1VQSS5JtbKiZGfz5Oyli1bFhxn9ewAXdmFSAYFuxCJoGAXIhEU7EIkgoJdiERQsAuRCDNp/7QMwN8DaAQwCWCHuz9uZrUAfgJgBaZaQH3R3S/Fbqu4qAgrloctA8vj1gRLNMlEbJCRUZ7sEiNWT45ZbH19fXROZWUl1WJJCwUF/O/w7bfQPprYv39/cLy6ktdHW7fmdqqd6uT25q238nV861vfCo7fd999dE5rayvVurr4Olav5nX++vv7g+N5edzabGjgyVCxZJeY7XX+PK+hx1pRdXR00DksSWY8YhvO5Mo+DuAv3H0DgFsBfNnMNgJ4DMAr7r4GwCvZ74UQ1yjTBru7d7n729mvMwAOAmgG8HkAO7M/thMA/5MthFhwrug9u5mtAHATgDcANLh7FzD1BwHAkrlenBBi7phxsJtZBYCfAfiKu/M3qZ+c94iZ7Taz3ZmB8PsnIcT8M6NgN7NCTAX6D9392ezwWTNryupNAIKlM9x9h7u3uXtbZTk/FBFCzC/TBrtN1WL6AYCD7v6dy6QXADyU/fohAM/P/fKEEHPFTLLe7gDwJQD7zeyd7NhXAXwTwDNm9jCAkwB4D54sDp79k+nl7wyampcGxy2SSbRu3TqqnThxgmqDgzw7bHJyMjgea/sT02pra6n22muv8dssKb3i+8uLtHFy5xZgfn647h4AtLcfo9qDDz4YHN+wYQOd89Zbb1GtuTlcSw6I12o7evRocLykpITOKS3l+xvLlmO15ABg6dLwcxjglm5sHcy2jWXKTRvs7v4rAOwR/8x084UQ1wb6BJ0QiaBgFyIRFOxCJIKCXYhEULALkQg5LTg5OTmBwcHwp+jOnTtH5912x63B8TNnwsUrAeDFF1+kGrOFAOCNN9+kGstgKy7kdsc/PvNjqsVaPK29bhXVLl7kGVRDQ2HrMGa9jZ4fplpLC7eMXnv911T70h//SXD8/Plw2yIAWLKknmrNzbw1VH8k6/Dee+4Oji+qqaNzYtmIseKisUKVsVZfzDqMFR1lc57e9Q90jq7sQiSCgl2IRFCwC5EICnYhEkHBLkQiKNiFSAS7mh5UV0t5cYlfvzRcVPDJJ5+k8x5//PHg+Jf/w6N0zi9+8Quq7X/vXao98MADVDt0+HBwvLLq6jLbYlp7ezvVYpl0Bw4cCI6vXbuWzokVUVy99jqqxXqbseywffv20TmL63mxo5g1W0cKkgLApUvhGqiDA9xujBcC5b9z7HEZGeG23PBweC2xDDZmpf7V3z6Ok6c7golrurILkQgKdiESQcEuRCIo2IVIBAW7EImQ00SYuro6/Mkffymovf/++3Qea6vzyiuv0Dnbt2+nWlf3WaodP36cak2NjcHxunqewPHuu/zkf8WKFVQ7TE7+AaC5iSenXL9hY3C8t7eXzrF8/jf/yJEjVDtwgJ+sb7nhxuD4aKRO2/Agb+c1OsznuddQjbkCxUW8vlss2aWpge99rE5eZydP2mK164aGuEvCWmWVRuoT6souRCIo2IVIBAW7EImgYBciERTsQiSCgl2IRJjWejOzZQD+HkAjgEkAO9z9cTP7OoA/BfBhhsJX3Z0XfsNU3aytW7cGte9973t03i23hWvQ7dy5MzgOAJs2baLaH2zbTrWXfsHtvM2bNwfHd+/ZQ+eMj49TrbCAtxK6/vrrqdZx8hTVli9fHhxnrasAIC+Pt3jKDPD6brE1siSOnp4eOqeysppqzH4F4lZZf3+45mFZKa/vNhlJhInV/2NJN0C8bRSrT5fn/Fp8+vTp4Pjo2CidMxOffRzAX7j722ZWCWCPmb2U1b7r7n8zg9sQQiwwM+n11gWgK/t1xswOAuCfHhBCXJNc0Xt2M1sB4CYAb2SHHjWzfWb2tJnxpGIhxIIz42A3swoAPwPwFXfvA/AkgNUAtmDqyv9tMu8RM9ttZrt7+vhHNoUQ88uMgt3MCjEV6D9092cBwN3PuvuEu08CeArAzaG57r7D3dvcva2mih/ACCHml2mD3cwMwA8AHHT371w2fnmLji8ACNdDEkJcE8zkNP4OAF8CsN/M3smOfRXAg2a2BYADaAfwZ9PdUFFhEZqblwW1/PxCOq+3N2ytNDTwlkDf//7TVHviiSeo9td/8x2qrV8XziirKAu3hQKAtet4Dbd9e/dSLZYtt3gxb13ErLff/OZ1Oqeujt9erG1UcQl/zPItPK8h0uIp08dtuXPdF6jW3NxCtTWrw/vf3X2ezsmLZI7F6tNFJPg4r/U41B/ObivI4zXoikrCVp6B26gzOY3/FRC8hainLoS4ttAn6IRIBAW7EImgYBciERTsQiSCgl2IRMhpwcnx8XHaxifWOqeyPJyhtGXLFjrn17/+NdW6urqo9uif/znVxknmWKyYYH4et6fOnDlDtViW1K23hrMAAeDkyZPB8djvXLOoimqFBfx6MDbGWxoxpylm5ZWUlFCtsYm3hopl9B0/cjQ4fvYsbyfV2rqCaha5PhYXcass1m6K/d6jozyDjVmA0exGqgghfqdQsAuRCAp2IRJBwS5EIijYhUgEBbsQiZBT621kZATtR48FtdWrV9N5mzffFBwfHuW9sO68czvVfvs2zzaLFQ2sqAhbgLFiiPEsKa5t27aNarE1dnd3B8fra2vpnJgtV17OM8AqKsKFEgGgqjxs58UKNhYX8/sqLOQW5kA/t7WcWFEb12+gcwoK+OPZ2cnt0liWmkWKR4K4ZaPD3Hpj++HOs+t0ZRciERTsQiSCgl2IRFCwC5EICnYhEkHBLkQi5Nx6O3o0nIX06U9/ms7b9ZNnguNVVTxby3ndPVx3HS8CedNNYZsPAAYHB4PjNXXc1hoYGKDatjt/n2ofHDpItZGRIaqVlobtK2YbAoAZt2vyI5lcLMMOABZVXXnPkFjRUdY7DgCKI9bnVHHkT5LpCz+WAJDJnKXa+Ci3S0ur+fNg0SKuMSs1llXI7N5YwUld2YVIBAW7EImgYBciERTsQiSCgl2IRJj2NN7MSgD8EkBx9uf/0d2/Zma1AH4CYAWm2j990d15hgaA/Lx8VFaGmzt2dPA6buvXrw+OxxJCVq7iJ+6bNm2i2rsH36Pa0qWNwXEr4CfFMd5++22qFUZOwTesXUe1vr6+4HjsZDfTH54DAMUF/IS8MlI3kNUUjJ2qx066vYDXVjPjt3nhQrhtVEUpbzJaW8OdhALjITMywvd4dIgn65QVkxp0hZEadGSvZpsIMwLgD9x9M6baM99tZrcCeAzAK+6+BsAr2e+FENco0wa7T9Gf/bYw+88BfB7Azuz4TgD3zcsKhRBzwkz7s+dnO7h2A3jJ3d8A0ODuXQCQ/Z/X+hVCLDgzCnZ3n3D3LQBaANxsZvxN78cws0fMbLeZ7e4f5J8mE0LML1d0Gu/uPQD+D4C7AZw1syYAyP4fLJHi7jvcvc3d2yrK+IGOEGJ+mTbYzWyxmdVkvy4F8FkA7wN4AcBD2R97CMDz87VIIcTsmUkiTBOAnTblb+QBeMbdf25mrwN4xsweBnASwP3T3VBRcRFWrlwZ1F5++WU6b+u/aQuOxxJh6uvrqfbqq69S7ejxcI08ALj33nuD45kMtwBjLZ5iNeiKI22jYnXQysrCNk7Mequu5jbU5CS3f1paWqg2NBiuDxhr/5QXa59EkpAAYGyM23KstVKs3Vhvby/VhiN14WK3eTVtr2KPM2vzNDnB92LaYHf3fQA+kQrm7hcAfGa6+UKIawN9gk6IRFCwC5EICnYhEkHBLkQiKNiFSASLZcnM+Z2ZnQNwIvttPYDzObtzjtbxUbSOj/KvbR3L3X1xSMhpsH/kjs12u3vYQNc6tA6tY87XoZfxQiSCgl2IRFjIYN+xgPd9OVrHR9E6PsrvzDoW7D27ECK36GW8EImwIMFuZneb2QdmdsTMFqx2nZm1m9l+M3vHzHbn8H6fNrNuMztw2Vitmb1kZoez/195/6S5WcfXzex0dk/eMbN7crCOZWb2v83soJm9a2b/KTue0z2JrCOne2JmJWb2ppntza7jG9nx2e2Hu+f0H4B8AEcBrAJQBGAvgI25Xkd2Le0A6hfgfu8EsBXAgcvG/hrAY9mvHwPwVwu0jq8D+M853o8mAFuzX1cCOARgY673JLKOnO4JAANQkf26EMAbAG6d7X4sxJX9ZgBH3P2Yu48C+DGmilcmg7v/EsDFjw3nvIAnWUfOcfcud387+3UGwEEAzcjxnkTWkVN8ijkv8roQwd4M4NRl33dgATY0iwP4ZzPbY2aPLNAaPuRaKuD5qJnty77Mn/e3E5djZiswVT9hQYuafmwdQI73ZD6KvC5EsId6yi6UJXCHu28F8O8AfNnM7lygdVxLPAlgNaZ6BHQB+Hau7tjMKgD8DMBX3J13rsj9OnK+Jz6LIq+MhQj2DgDLLvu+BQBvBzOPuHtn9v9uAM9h6i3GQjGjAp7zjbufzT7RJgE8hRztiZkVYirAfujuz2aHc74noXUs1J5k7/uKi7wyFiLY3wKwxsxWmlkRgAcwVbwyp5hZuZlVfvg1gD8EcCA+a165Jgp4fvhkyvIF5GBPzMwA/ADAQXf/zmVSTveErSPXezJvRV5zdcL4sdPGezB10nkUwH9ZoDWswpQTsBfAu7lcB4AfYerl4BimXuk8DKAOU220Dmf/r12gdfwPAPsB7Ms+uZpysI7fw9RbuX0A3sn+uyfXexJZR073BMCNAH6bvb8DAP5rdnxW+6FP0AmRCPoEnRCJoGAXIhEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiE/wci237JStju5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = tf.io.read_file(n[0])\n",
    "t = tf.image.decode_image(t)\n",
    "plt.imshow(t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(data):\n",
    "    img_path = data[0]\n",
    "    label = data[1]\n",
    "    label = tf.strings.to_number(label, out_type=tf.int64)\n",
    "    \n",
    "    tf_img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_image(tf_img)\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 32, 3]), <tf.Tensor: shape=(), dtype=int64, numpy=1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(read_img)\n",
    "n = next(iter(dataset))\n",
    "n[0].shape, n[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, valid데이터셋 나눠서 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(input_paths, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 3500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(np.array(train))\n",
    "train_dataset = train_dataset.map(read_img)\n",
    "train_dataset = train_dataset.shuffle(len(train))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = tf.data.Dataset.from_tensor_slices(np.array(valid))\n",
    "valid_dataset = valid_dataset.map(read_img)\n",
    "valid_dataset = valid_dataset.batch(32)\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,166,177\n",
      "Trainable params: 2,164,961\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input((32, 32, 3))\n",
    "\n",
    "# Feature Extraction\n",
    "net = Conv2D(32, 3, 1, 'SAME')(inputs)\n",
    "net = Activation('relu')(net)\n",
    "net = Conv2D(32, 3, 1, 'SAME')(net)\n",
    "net = Activation('relu')(net)\n",
    "net = MaxPooling2D((2,2))(net)\n",
    "net = BatchNormalization()(net)\n",
    "\n",
    "net = Conv2D(64, 3, 1, 'SAME')(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Conv2D(64, 3, 1, 'SAME')(net)\n",
    "net = Activation('relu')(net)\n",
    "net = MaxPooling2D((2,2))(net)\n",
    "net = BatchNormalization()(net)\n",
    "\n",
    "# classification\n",
    "net = Flatten()(net)\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Dense(1)(net)\n",
    "output = Activation('sigmoid')(net)\n",
    "\n",
    "basic_cnn = tf.keras.Model(inputs=inputs, outputs = output, name='basic_cnn')\n",
    "\n",
    "basic_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "             optimizer = tf.keras.optimizers.Adam(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=5, mode='auto')\n",
    "mc = ModelCheckpoint('basic_cnn.h5', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "437/437 [==============================] - 5s 12ms/step - loss: 0.1493 - accuracy: 0.9467 - val_loss: 0.3029 - val_accuracy: 0.8647\n",
      "Epoch 2/50\n",
      "437/437 [==============================] - 2s 6ms/step - loss: 0.0781 - accuracy: 0.9722 - val_loss: 1.0170 - val_accuracy: 0.7572\n",
      "Epoch 3/50\n",
      "437/437 [==============================] - 3s 6ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.1313 - val_accuracy: 0.9590\n",
      "Epoch 4/50\n",
      "437/437 [==============================] - 2s 6ms/step - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.2245 - val_accuracy: 0.9341\n",
      "Epoch 5/50\n",
      "437/437 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.7663 - val_accuracy: 0.8159\n",
      "Epoch 6/50\n",
      "437/437 [==============================] - 2s 6ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.4826 - val_accuracy: 0.8638\n",
      "Epoch 7/50\n",
      "437/437 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.2409 - val_accuracy: 0.9031\n",
      "Epoch 8/50\n",
      "437/437 [==============================] - 2s 6ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 1.5806 - val_accuracy: 0.7821\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train) // 32\n",
    "validation_steps = len(valid) // 32\n",
    "\n",
    "hist = basic_cnn.fit(train_dataset,\n",
    "                validation_data = valid_dataset,\n",
    "                validation_steps=validation_steps,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=50,\n",
    "                callbacks=[es, mc]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/4d502fd57fe2fe31318f8246a343a57f.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_img_read(path) :\n",
    "    tf_img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(tf_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "test_ds = test_ds.map(test_img_read)\n",
    "test_ds = test_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = basic_cnn.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.reshape(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fname = sub['id']\n",
    "test_label = pred\n",
    "\n",
    "sub_file = pd.DataFrame({'id':test_fname, 'has_cactus':test_label}, columns=['id', 'has_cactus'])\n",
    "sub_file.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
